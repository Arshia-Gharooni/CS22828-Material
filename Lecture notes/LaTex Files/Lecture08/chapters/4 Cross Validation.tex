\section{صحت‌سنجی}

در بخش پیش با مفهوم منظم‌سازی و ابرپارامتر آشنا شدیم. ابرپارامتر‌ها بر خلاف پارامترهای معمولی، که از طریق آموزش به دست می‌آیند و عملکرد مدل را کنترل می‌کنند، برای کنترل خود فرآیند آموزش بکار گرفته می‌شوند و با استفاده درست از آن‌ها می‌توان سرعت و کیفیت فرآیند یادگیری را افزایش داد. 
برای مثال درجه‌ی چندجمله‌ای در مسئله‌ رگرسیون، تعداد لایه‌های شبکه‌های عصبی، ضریب منظم‌سازی، تعداد مراحل اجرای الگوریتم، و ... ابرپارامتر به شمار می‌آیند ولی وزن‌های مسئله رگرسیون و یا وزن‌های شبکه‌های عصبی پارامتر‌های مدل می‌باشند.

پارامتر‌های بهینه در فرآیند آموزش و بر اساس الگوریتم یادگیری، به گونه‌ای یادگرفته می‌شوند که خطای مدل را بر روی داده‌های آموزش کاهش دهند. برای اینکه بتوانیم ابرپارامتر‌های مناسب را پیدا کنیم، می‌توانیم داده‌های آموزش را به دو دسته تقسیم کرده و با استفاده از یکی از آن‌ها پارامتر‌ها را پیدا کنیم و با استفاده از دیگری ابرپارامتر‌ها را بیابیم. در این تقسیم‌بندی جدید به مجموعه‌ داده‌های دسته اول، مجموعه‌ داده‌های آموزش گفته می‌شود (که زیرمجموعه‌ای از داده‌های آموزش سابق است)، به دسته دوم مجموعه داده‌های صحت‌سنجی می‌گوییم.

با استفاده از این تقسیم‌بندی می‌توانیم برای تعداد ابرپارامتر دلخواه، فرآیند آموزش را به کمک داده‌های آموزش انجام دهیم، و به کمک داده‌های صحت‌سنجی ابرپارامتر را که منجر به یافتن بهترین پارامتر‌ها می‌شود را بیابیم. در واقع میزان خطای مدل آموزش داده شده بر روی داده‌های صحت‌سنجی معیاری برای تخمین خطای مدل بر روی داده‌های آزمون است. پس به این روش می‌توانیم بهترین ابرپارامترهای مدل را پیدا کنیم.

اما این روش بدون ایراد نبوده و ما را با چالش‌های جدیدی مواجه می‌کند. در واقع با تقسیم داده‌ها به دو مجموعه آموزش و صحت‌سنجی، تعداد داده‌های آموزش محدود شده و این منجر به کاهش عملکرد مدل خواهد شد. اثرات این پدیده در صورت کم بودن داده‌های در دسترس، و یا بزرگ بودن مجموعه‌ داده‌های صحت‌سنجی تشدید می‌شود. اگر هم تعداد داده‌های صحت‌سنجی را کاهش دهیم، تخمین ما از عملکرد مدل افت پیدا کرده و غیر قابل اطمینان می‌شود. یک راه حل برای این موضوع استفاده از صحت‌سنجی ضربدری\LTRfootnote{cross-validation} است که در ادامه به آن می‌پردازیم.

\subsection{صحت‌سنجی ضربدری}

یک روش برای انجام صحت‌سنجی هنگامی که به تعداد اندکی داده دسترسی داریم، این است که داده‌هایمان را به طور تصادفی به  $k$ قسمت تقسیم کنیم، سپس با توجه به تقسیم‌بندی انجام شده به تعداد $k$ بار، هر دفعه یک بخش از داده‌ها را به عنوان داده‌های صحت‌سنجی کنار گذاشته و مدل را بر روی $1-k$ بخش دیگر آموزش دهیم. در این صورت می‌توانیم از میانگین نتایج صحت‌سنجی استفاده کرده و مدلی که بهترین عملکرد را دارد را به عنوان مدل نهایی انتخاب کنیم. به این الگوریتم $k-\text{\begin{latin}fold\end{latin} } ~\text{\begin{latin}
        cross-validation
    \end{latin}}$ می‌گویند.

این روش از صحت‌سنجی نیز معایبی دارد. برای نمونه هزینه محاسباتی به صورت چشمگیری افزایش می‌یابد. به همین دلیل استفاده از این روش برای مدل‌هایی که آموزش آن‌ها زمان زیادی می‌برد (برای مثال در آموزش شبکه‌های عصبی ژرف) امکان‌پذیر نیست. علاوه بر این قضیه انتخاب مقدار مناسب برای $k$ نیز می‌تواند تبدیل به کار دشواری شود.

