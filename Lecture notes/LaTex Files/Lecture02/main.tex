\documentclass[12pt]{article}
\usepackage{graphicx}
\graphicspath{ {./images/} }
\input{etc/cmd}


\begin{document}
\fontsize{12pt}{14pt}\selectfont
\input{etc/head}

\section*{مسئله یادگیری $supervised$}
اکنون یک نمونه از مشکلات یادگیری تحت نظارت را بررسی میکنیم. فرض کنید مجموعه داده ای داریم که مناطق زندگی و قیمت 47 خانه را از تهران ارائه می دهد:

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.4\textwidth]{etc/Images/Fig1.png} 
  \caption{داده های 47 خانه در تهران}
  \label{fig1}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.4\textwidth]{etc/Images/Fig3.png} 
  \caption{داده های پلات شده}
  \label{fig3}
\end{figure}


*$h(x)$ مجموعه همه ی خط ها در فضای دو بعدی است و فضای فرضیه ساخته شده 
$h : X\longrightarrow Y$
برابر با تمام خطوط ممکن در فضای دو بعدی می باشد .

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.4\textwidth]{etc/Images/Fig2.png} 
  \label{fig2}
\end{figure}
هنگامی که متغیر هدفی که می‌خواهیم پیش‌بینی کنیم پیوسته باشد، مانند مثال قیمت خانه های شهر، مسئله یادگیری را مسئله \textbf{رگرسیون} می‌نامیم. وقتی $y$ بتواند فقط تعداد کمی از مقادیر گسسته را به خود بگیرد و تعداد $output$ ها محدود باشد، ما آن را یک مسئله $classification$ می‌نامیم.

\subsection*{$regression$ $Linear$}
برای انجام یادگیری تحت نظارت، باید تصمیم بگیریم که چگونه فرضیه های $h$ را مدل کنیم در کامپیوتر. به عنوان یک انتخاب اولیه، فرض کنید تصمیم داریم $y$ را به عنوان تابع خطی $x$ تقریب کنیم:
\\
\[
h_w(x) = w_0 + w_1x_1 + w_2x_2
\]

جایی که $w_i$ ها پارامترها یا وزن های مدل نامیده می شوند که فضای توابع خطی نگاشت $h : X\longrightarrow Y$ را پارامتر می کنند. در اینجا $w_0$ عرض از مبدا و 
$w_1$
شیب می باشد .
\\
\\
برای ساده کردن $notation$، ما $x_0$ را 1 قرار میدهیم  معرفی می کنیم، به طوری که حاصل میشود:
\[
h(x)=\sum_{i=0}^{d}{w}_{i}x_{i}={w}^{T}x,
\]

ولی خب بدیهتا تابع ما با دیتای واقعا اختلافاتی دارد و خطاهایی موجود است که به صورت زیر میتوان اندازه گیری کردشان:
\[
loss = (y - h(x))^2
\]
حال، با توجه به یک داده های آموزشی، چگونه پارامترهای $w$ را انتخاب کنیم یا یاد بگیریم؟ به نظر می رسد یک روش معقول این است که $h(x)$ را به $y$ نزدیک کنیم، حداقل برای مثال های آموزشی که داریم. اکنون تابعی را تعریف می‌کنیم که برای هر مقدار $w$، میزان نزدیکی $h(x(i))$ به $y(i)$ مربوطه را اندازه می‌گیرد. $cost function$ را تعریف می کنیم:
\[
J(\theta)=\frac{1}{2}\sum_{i=1}^{n}(h_{\theta}(x^{(i)})-y^{(i)})^{2}
\]

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.5\textwidth]{etc/Images/Fig4.png} 
  \caption{یک نمایش از اینکه چگونه یک مدل خطی با مجموعه ای از داده ها مطابقت دارد.}
  \label{fig4}
\end{figure}

\subsection*{$algorithm$ $learning$  $The$}
هدف اصلی ما این است که $w$ را طوری انتخاب کنیم که $J(w)$ را به حداقل برسانیم.
 برای هر فرضیه در فضای فرضیه یک تابع هزینه در نظر میگیرم و با مینیمم کردن تابع هزینه پارامتر های بهترین فرضیه رو یاد میگیره که حل این مساله $optimization$ است.

اولین راهی که به ذهن می رسد مشتق گیری و برابر صفر قرار دادن تابع ما است یعنی : 
$$\frac{\partial J(w)}{\partial w_0} 
 = 0 $$
 $$\frac{\partial J(w)}{\partial w_1} 
 = 0 $$

  در واقع مقدار تابع گرادیان برابر صفر است و دو دستگاه معادلات خطی داریم و میتوانیم این دو را به دست آوریم .
 برای حالت 
 $multivariate$
 ماتریس در نظر می گیریم به نوعی که برای هر سمپل به اندازه ی 
 $d$
 فیچر داریم .
 هر سطر 1 سمپل را نشان می دهد 
 پس :

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.50\textwidth]{etc/Images/Fig5.png} 
  \caption{ماتریس های سمپل ها، وزن ها و $y$}
  \label{fig5}
\end{figure}

که میتوان میزان هزینه را به شکل زیر بدست آورد:

\[
J(w)=\sum_{i=1}^{n}(y^{(i)}-h_{w}(x^{(i)}))^2=\sum_{i=1}^{n}(y^{(i)}-w^{T}x^{(i)})^2
\]

برای پیاده سازی این الگوریتم، باید مشخص کنیم که عبارت مشتق جزئی در سمت راست چیست. بیایید ابتدا آن را برای حالت اگر ما فقط یک مثال آموزشی داریم $(x, y)$ کار کنیم تا بتوانیم از مجموع در تعریف $J$ صرف نظر کنیم. داریم:
\begin{align*}
\frac{\partial}{\partial w_j}J(w) &= \frac{\partial}{\partial w_j} (h_w(x) - y)^2 \\
&= 2 (h_w(x) - y) . \frac{\partial}{\partial w_j}(h_w(x) - y)^2 \\
&= 2 (h_w(x) - y)^2  . \frac{\partial}{\partial w_j} \left(\sum_{i=1}^{d} w_i x_i - y \right)
\\
&=2 (h_w(x) - y) x_i
\end{align*}

مشتق تابع هزینه را با توجه به $w$ ها را صفر قرار دهید.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.4\textwidth]{etc/Images/Fig6.png} 
  \label{fig6}
\end{figure}

چرا 
$X^TX $
وارون پذیر است ؟

ماتریس سمپل $X$ ها فول رنک می باشد و وارون پذیر است .
البته با چالش هایی نیز مواجه هستیم .

\subsection*{بهینه سازی تابع هزینه}
تا به اینحا به سادگی جواب  به صورت 
$closed form$
به دست می آمد و مشکلی نداشتیم . اما در اکثر مواقع این اتفاق به راحتی نمی افتد و نیاز به 
 راهکرد دومی داریم که میتوانیم 
 به صورت 
$iterative$
عمل کنیم .
مدل دلخواهی در فضای فرضیه انتخاب کرده و با پارامتر های دلخواه در هر گام طوری حرکت کنیم که تابع هزینه ما کاهش یابد . بدین صورت بعد از مدتی امیدوار هستیم به کمینه تابع هزینه برسیم :
هرگاه وابسته به اینکه در کجا هستیم جهت حرکت مشخص می شود .


احتمالا اولین الگوریتمی که به ذهنمون میرسد الگوریتم $descent$ $gradient$ است.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.6\textwidth]{etc/Images/Fig7.png} 
  \label{fig7}
\end{figure}

\subsubsection*{مرور الگوریتم $descent$ $gradient$ }
از 
$w_0$
شروع کرده و هدف ما کمینه کردن تابع 
 $J(w)$
 است .
در خلاف جهت گرادیان حرکت می کنیم پس داریم : 
 $$
w^{t+1} = w^t - \eta \nabla J (w^T)
$$
$$\nabla_wJ(w) = \left[\begin{array}{l}
\frac{\partial J(w)}{w_1} \\
\quad \vdots \\
 \frac{\partial J(w)}{w_d}\\
\end{array}\right] $$
$$\eta : learning rate  $$
* در $Gradient acsent $ بر خلاف مورد بالا تابعی داریم که میخواهیم آنرا ماکسیمم کنیم . مثلا  تابع $score$ ... و در جهت گرادیان حرکت می کنیم .

*اگر به اندازه ی کافی 
$\eta$
کوچک باشد ، داریم :
$$J(w^{t+1}) \leq J(w) $$
* $\eta$ 
را می توان
در هر تکرار 
به صورت
$\eta_t$ تغییر
داد.

معایب کاهش گرادیان:
- مشکل کمینه‌های محلی: در الگوریتم کاهش گرادیان، ممکن است به کمینه‌های محلی در تابع هدف برخورد کنیم. این به این معناست که الگوریتم ممکن است در نقاطی که تابع هدف کمینه‌های محلی دارد، متوقف شود و به کمینه‌ی کلی نرسد.
- اما وقتی تابع$j$ $convex$ است، تمام کمینه‌های محلی همان کمینه‌های سراسری هستند.
که
الگوریتم کاهش گرادیان می‌تواند به جواب سراسری همگرا شود.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.6\textwidth]{etc/Images/Fig8.png} 
  \caption{$descent$ $gradient$ با تابع هزینه غیر محدب - مسیر اول}
  \label{fig8}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.6\textwidth]{etc/Images/Fig9.png} 
  \caption{$descent$ $gradient$  با تابع هزینه غیر محدب - مسیر دوم}
  \label{fig9}
\end{figure}

انتخاب $rate$ $learning$ مناسب در $descent$ $gradient$ برای همگرایی کارآمد بسیار مهم است.
\begin{itemize}
    \item اگر $rate$ $learning$ خیلی کم باشد:
    \begin{itemize}
        \item    پیشرفت کند است و منجر به همگرایی در طولانی مدت می شود.
        \item   ممکن است در مینیمم های محلی بیفتد و راه حل های کمتر از حد مطلوب را به دست دهد.
    \end{itemize}

    \item اگر میزان یادگیری خیلی زیاد باشد:
    \begin{itemize}
        \item 
    خطر $overshoot$ راه حل بهینه، ایجاد واگرایی.
        \item 
    به روز رسانی ها نوسان یا واگرا می شوند که منجر به بی ثباتی می شود.
        \item
    $function$ $loss$ به شدت نوسان می کند و مانع همگرایی می شود.
    \end{itemize}
\end{itemize}

\section*{بهینه سازی تابع هزینه}
$$ 
w^{t+1} = w^t - \eta \nabla J(w^t)$$
$$
J(w) = \sum_{i=1}^{n} (y^{(i)} - h_w (x^{(i)}))^2$$
$$
w^{t+1} = w^t + \eta \sum_{i=1}^{n}(y^{(i)} - w^T x^{(i)}) x^{(i)}$$
با داشتن کل داده های آموزشی در هر گام 
بر اساس کل $n$ دیتا ی آموزشی یک گام برداشته می شود و در نهایت به جواب بهینه می رسیم .

\section*{کاهش گرادیان تصادفی}

کاهش گرادیان تصادفی $SGD$ نوعی از الگوریتم کاهش گرادیان است که برای بهینه‌سازی مدل‌های یادگیری ماشین استفاده می‌شود. این الگوریتم به مشکلات کارایی محاسباتی روش‌های سنتی کاهش گرادیان در مواجهه با مجموعه‌های داده بزرگ در پروژه‌های یادگیری ماشین پاسخ می‌دهد.
در $SGD$، به جای استفاده از کل مجموعه داده در هر تکرار، فقط یک مثال آموزشی تصادفی (یا یک دسته کوچک) برای محاسبه گرادیان و به‌روزرسانی پارامترهای مدل انتخاب می‌شود. این انتخاب تصادفی، تصادفی‌گردی را به فرآیند بهینه‌سازی معرفی می‌کند، به همین دلیل از عبارت "تصادفی" در کاهش گرادیان تصادفی استفاده می‌شود.
مزیت استفاده از $SGD$ کارایی محاسباتی آن است، به ویژه در مواجهه با مجموعه‌های داده بزرگ. با استفاده از یک مثال یا یک دسته کوچک، هزینه محاسباتی در هر تکرار به طور قابل توجهی کاهش می‌یابد نسبت به روش‌های سنتی کاهش گرادیان که نیاز به پردازش کل مجموعه داده دارند.

\end{document}
